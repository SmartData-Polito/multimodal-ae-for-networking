{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77de2d6b",
   "metadata": {},
   "source": [
    "# <b>Task01 - Traffic Application Classification</b>\n",
    "___\n",
    "\n",
    "In the first task, we solve a traffic classification problem determining which mobile app generated particular traffic flows. \n",
    "\n",
    "We use the `MIRAGE` dataset, collected from volunteers over a period of two years, from 2017 to 2019. It consists of 44k flows of data, each characterized by several measurements, including inter-arrival times, packet lengths, TCP receiver window values, and application payloads. The goal is to classify each flow into one of 16 different classes representing different mobile apps, or as background traffic. The classes are well-balanced, with a coefficient of 0.94.\n",
    "\n",
    "**Note** In this notebook we report only the validation of the models and the experiments _without the training_. If you want to inspect our training approach or run again a model training see README (**Training the models** section).\n",
    "\n",
    "# Table of Content\n",
    "- Configuration\n",
    "- Load features\n",
    "- Validate the models\n",
    "- k-nearest-neighborhood class probability\n",
    "- Shallow learners\n",
    "- Unsupervised clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe6dbb-5cb5-4d72-9631-ec3811acfb1f",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Before we begin, we need to set up our environment and load the necessary libraries and modules. We also need to specify the paths to the data files and define some global variables that will be used throughout the notebook. \n",
    "\n",
    "The `DEMO` flag controls whether we are running the notebook in demonstration mode (`True`) or full mode (`False`). In demonstration mode some experiments will be run with less samples and the output will not be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "822a33e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mltoolbox and utls reachable from this folder\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from utils import*\n",
    "\n",
    "# Features and embeddings paths\n",
    "FEATURES = '../data/task01/features'\n",
    "EMBEDDINGS = '../data/task01/embeddings'\n",
    "INTERIM = '../data/interim'\n",
    "\n",
    "# Demonstrative flag\n",
    "DEMO = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd149fc9",
   "metadata": {},
   "source": [
    "## Load features\n",
    "\n",
    "In this section, we will load the data files that contain the features for our machine learning models. We will use the `pandas` library to read in the CSV files and store the data in dataframes. \n",
    "- The `ipaddress` dataframe will contain the word2vec embeddings for the IP addresses\n",
    "- The `payload` dataframe will contain the payload bytes\n",
    "- The `statistics` dataframe will contain Tstat-style features\n",
    "- The `sequences` dataframe will contain statistical features in sequence referred to each byte. \n",
    "\n",
    "The data in these dataframes will be used as input to our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b25c42f-a76b-45ea-a28d-66670f344b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load ip address word2vec embeddings - entity\n",
    "ipaddress=pd.read_csv(f'{FEATURES}/ipaddress.csv', index_col=[0])\n",
    "# Load payload bytes - quantity\n",
    "payload=pd.read_csv(f'{FEATURES}/payload.csv', index_col=[0])\n",
    "# Load statistics features - quantity\n",
    "statistics=pd.read_csv(f'{FEATURES}/statistics.csv', index_col=[0])\n",
    "# Load statistics sequences - quantity\n",
    "sequences=pd.read_csv(f'{FEATURES}/sequences.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01063a4d-e1d0-4b35-9692-cd41a559410d",
   "metadata": {},
   "source": [
    "Then we merge the dataframes containing our features into a single dataframe called concat. We start by resetting the index of the payload dataframe and dropping the 'label' column. Then, we perform an inner join on the 'index' column with the statistics dataframe, also dropping the 'label' column. We repeat this process for the sequences dataframe and the ipaddress dataframe. Finally, we set the 'index' column as the index of the resulting dataframe. This results in a single dataframe that contains all of the features for our models, with the 'index' column serving as the primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f528cb9-d28e-4bd3-8ca2-2aeeb27c84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the features as raw concatenation\n",
    "concat = payload.reset_index().drop(columns=['label'])\\\n",
    "                .merge(statistics.reset_index().drop(columns=['label']), \n",
    "                       on='index', how='inner')\\\n",
    "                .merge(sequences.reset_index().drop(columns=['label']), \n",
    "                       on='index', how='inner')\\\n",
    "                .merge(ipaddress.reset_index(), on='index', how='inner')\\\n",
    "                .set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a1317-6b74-4a82-a378-9960a33ef2d5",
   "metadata": {},
   "source": [
    "Finally, we collect the features sets in a dictionary, we load the stratified-k-folds order we provide and retrieve the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89fb0f4-04ee-4f47-9553-09ee2d0a5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Collect the features in a dictionary\n",
    "features = {'payload':payload, 'statistics':statistics,\n",
    "            'sequences':sequences, 'ipaddress':ipaddress,\n",
    "            'rawcat':concat, 'mae':None}\n",
    "\n",
    "# Load stratified k folds\n",
    "kfolds = joblib.load(f'../data/task01/skfolds/folds.save')\n",
    "\n",
    "# Get the number of classes\n",
    "n_classes = ipaddress.value_counts('label').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e42bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Validate the models\n",
    "\n",
    "After having trained the models through the training scripts, we need to validate them.\n",
    "\n",
    "The following function is responsible for evaluating the pre-trained classifiers using cross-validation.  The model predicts the labels of each one of the provided fold at a time. It then generates a summary of the model's performance on the validation set in the form of a classification report, which includes metrics such as precision, recall, and f1-score. The function can be called multiple times with different values of K in order to validate the model's performance on all of the folds of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f205b4-2f4c-4bda-83b0-a7e817227fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from mltoolbox.classification import DeepClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def validate_single_run(feature, fname, K, pbar):\n",
    "    # Retrieve the training and validation samples from the k-folds order\n",
    "    X_train, X_val, y_train, y_val = get_datasets(kfolds, K, feature)\n",
    "    \n",
    "    # Load the classifier model from the specified file path\n",
    "    mpath = f'../data/task01/classifiers/{fname}_k{K}'\n",
    "    classifier = DeepClassifier(_load_model=True, model_path=mpath)\n",
    "    \n",
    "    # Use the classifier to predict labels for the validation set\n",
    "    y_pred = classifier.predict(X_val, scale_data=True)\n",
    "    report = classification_report(y_val, y_pred, labels=np.unique(y_val), \n",
    "                                   output_dict=True)\n",
    "    \n",
    "     # Extract the macro average f1-score from the report\n",
    "    f1 = round(report['macro avg']['f1-score'], 2)\n",
    "    \n",
    "    # Update the progress bar object and set the postfix message\n",
    "    pbar.update(1)\n",
    "    pbar.set_postfix({'current fold':K, 'macro avg. f1': f1})\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb86bff-2c6f-403b-a17a-8479d9c88f16",
   "metadata": {},
   "source": [
    "Now we can validate the models. Namely, we run a full stratified-k-folds cross validation over:\n",
    "- Raw features independently\n",
    "- Concatenation of the raw features\n",
    "- Multi-modal embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3670704d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2389520ed640b9802df376412d48d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f94c35d4ad54a92b0ab0aad48c75749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab30ad8795384fb1980c26437b984826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc42f1f136d4c94a490804b42abcb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba8f6508286488f866118044b698595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feca5205245046a2bfd04754ff252328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fname, feature in features.items():\n",
    "    # Initialize a progress bar with a total of 5 iterations (skf)\n",
    "    pbar = tqdm(total=5)\n",
    "    pbar.set_description(f'Validating {fname}')\n",
    "    \n",
    "    # Iterate over the stratified folds\n",
    "    for K in range(5):\n",
    "        if fname == 'mae':\n",
    "            # Load the pre-trained multimodal embeddings\n",
    "            feature=pd.read_csv(f'{EMBEDDINGS}/mae_embeddings_k{K}.csv', \n",
    "                               index_col=[0])\n",
    "        # Validate the classifier getting the classification metrics\n",
    "        report = validate_single_run(feature, fname, K, pbar)\n",
    "        \n",
    "        # Save the report to a CSV file if not demonstrative\n",
    "        if not DEMO:\n",
    "            pd.DataFrame(report).T.to_csv(f'{INTERIM}/{fname}_deep_k{K}.csv')\n",
    "            \n",
    "    # Close the progress bar       \n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1771e2",
   "metadata": {},
   "source": [
    "## k-nearest-neighborhood class probability\n",
    "\n",
    "We now evaluate the embeddings space through the k-nearest-neighborhood class probability. It consists on applying a k-nearest-neighbors classifier on the whole dataset. Then, for each sample whose label is different from `unknown` (if present) we compute the probability of having samples with the same label in their neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5e79d1e-782a-4356-a07f-c00a3f15f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltoolbox.classification import KnnClassifier\n",
    "from mltoolbox.metrics import k_class_proba_report\n",
    "\n",
    "def kpc_single_run(feature, fname, K, k, pbar):\n",
    "    # Retrieve the training and validation datasets for the current fold\n",
    "    X_train, X_val, y_train, y_val = get_datasets(kfolds, K, feature)\n",
    "    X, y = np.vstack([X_train, X_val]), np.hstack([y_train, y_val])\n",
    "    \n",
    "    # If demonstrative load less samples\n",
    "    if DEMO: X, y = X[:3000], y[:3000]\n",
    "    \n",
    "    # Train a KNN classifier with cosine similarity and the specified number \n",
    "    # of neighbors\n",
    "    knn = KnnClassifier(n_neighbors=k, metric='cosine')\n",
    "    knn.fit(X, y, scale_data=True)\n",
    "    \n",
    "    # Keep only the samples with labels other than 'unknown' and predict labels\n",
    "    to_keep = np.where(y!='unknown')[0].reshape(-1, 1)\n",
    "    pcs = knn.predict_proba(to_keep)\n",
    "    \n",
    "    # Generate a report with the k-class probabilities\n",
    "    y_true = y[np.ravel(to_keep)]# Extract the true labels\n",
    "    report = k_class_proba_report(y_true, pcs, output_dict=True)\n",
    "    \n",
    "    # Extract the macro average k-class probability from the report\n",
    "    kpc = report['macro avg']['kpc']\n",
    "    \n",
    "    # Update the progress bar and set the postfix message\n",
    "    pbar.update(1)\n",
    "    pbar.set_postfix({'current fold':K, f'{k}Pc': kpc})\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89edc1da-0123-409a-a73b-1f78ebf1ae7a",
   "metadata": {},
   "source": [
    "We evaluate the neighborhood for the Multi-modal embeddings and the concatenation of the raw features. We average the experiment on the 5 folds. \n",
    "\n",
    "Note that, since we want to evaluate the embeddings neighborhood, we do not need to distinguish between training/validation samples, thus we merge together the subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daa16574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803073a62544478b87e76f6611aedd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ef64ba91c04fee93a4fc0337d14a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranges = range(1, 20) # Ranges of neighborhood radius\n",
    "# If demonstrative limit the runs\n",
    "if DEMO: ranges = range(1, 5)\n",
    "\n",
    "# Evaluate only the 'rawcat' and 'mae' features\n",
    "for fname, feature in features.items():\n",
    "    if fname in ['rawcat', 'mae']:\n",
    "        # Initialize a progress bar\n",
    "        pbar = tqdm(total=len(ranges)*5)\n",
    "        pbar.set_description(f'Evaluating {fname} neighborhood')\n",
    "        \n",
    "        # Iterate over the stratified folds\n",
    "        for K in range(5):\n",
    "            for k in ranges: # Try different neighborhood radious\n",
    "                if fname == 'mae':\n",
    "                    # Load the pre-trained multimodal embeddings\n",
    "                    feature=pd.read_csv(f'{EMBEDDINGS}/mae_embeddings_k{K}.csv', \n",
    "                                       index_col=[0])\n",
    "                # Compute the class probability\n",
    "                report = kpc_single_run(feature, fname, K, k, pbar)\n",
    "                \n",
    "                # Save the report to a CSV file if not demonstrative\n",
    "                if not DEMO:\n",
    "                    pd.DataFrame(report).T.to_csv(f'{INTERIM}/{fname}_{k}pc_k{K}.csv')\n",
    "        \n",
    "        # Close the progress bar \n",
    "        pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3aba58",
   "metadata": {},
   "source": [
    "## Shallow learners\n",
    "\n",
    "For the sake of completeness we investigate if shallow learners (instead of deep classifiers) can perform a good classification of the samples. \n",
    "\n",
    "Firstly we use a Random Forest classifier repeating the stratified k fold validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba9abb0c-246a-4c8b-bd8c-cc67a8123b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Validating MAE Random Forest classifier:\n",
      "\tMacro avg f1:0.8426948417914268\n",
      "Fold 1: Validating MAE Random Forest classifier:\n",
      "\tMacro avg f1:0.8490613856235416\n",
      "Fold 2: Validating MAE Random Forest classifier:\n",
      "\tMacro avg f1:0.8505468380988368\n",
      "Fold 3: Validating MAE Random Forest classifier:\n",
      "\tMacro avg f1:0.8680946209559376\n",
      "Fold 4: Validating MAE Random Forest classifier:\n",
      "\tMacro avg f1:0.8642330777755712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for K in range(5):\n",
    "    # Load the pre-trained multimodal embeddings\n",
    "    embeddings=pd.read_csv(f'{EMBEDDINGS}/mae_embeddings_k{K}.csv', \n",
    "                       index_col=[0])\n",
    "    # Retrieve the training and validation datasets for the current fold\n",
    "    X_train, X_val, y_train, y_val = get_datasets(kfolds, K, embeddings)\n",
    "\n",
    "    # Initialize a random forest classifier and fit it to the training data\n",
    "    clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Use the classifier to predict labels for the validation set\n",
    "    y_pred = clf.predict(X_val)\n",
    "\n",
    "    # Generate a classification report for the predictions\n",
    "    report = classification_report(y_val, y_pred, labels=np.unique(y_val), \n",
    "                                   output_dict=True)\n",
    "\n",
    "    # Extract the macro average f1-score from the report\n",
    "    f1 = report['macro avg']['f1-score']\n",
    "\n",
    "    # Print the macro average f1-score\n",
    "    print(f'Fold {K}: Validating MAE Random Forest classifier:\\n\\tMacro avg f1:{f1}')\n",
    "\n",
    "    # Save the report to a CSV file if not demonstrative\n",
    "    if not DEMO:\n",
    "        pd.DataFrame(report).T.to_csv(f'{INTERIM}/mae_rf_k{K}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295d5fdf-b699-4ab4-8dfa-f60549c721ea",
   "metadata": {},
   "source": [
    "Then we use a generic distance based 7-NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdcf0f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Validating MAE 7-NN classifier:\n",
      "\tMacro avg f1:0.10697046695664006\n",
      "Fold 1: Validating MAE 7-NN classifier:\n",
      "\tMacro avg f1:0.11126296218833427\n",
      "Fold 2: Validating MAE 7-NN classifier:\n",
      "\tMacro avg f1:0.101910778837631\n",
      "Fold 3: Validating MAE 7-NN classifier:\n",
      "\tMacro avg f1:0.11079072741958787\n",
      "Fold 4: Validating MAE 7-NN classifier:\n",
      "\tMacro avg f1:0.10907128829366836\n"
     ]
    }
   ],
   "source": [
    "from mltoolbox.classification import KnnClassifier\n",
    "\n",
    "for K in range(5):\n",
    "    # Load the pre-trained multimodal embeddings\n",
    "    embeddings=pd.read_csv(f'{EMBEDDINGS}/mae_embeddings_k{K}.csv', \n",
    "                       index_col=[0])\n",
    "    \n",
    "    # Retrieve the training and validation datasets for the current fold\n",
    "    X_train, X_val, y_train, y_val = get_datasets(kfolds, K, embeddings)\n",
    "    \n",
    "    # Initialize a KNN classifier with cosine similarity and 7 neighbors\n",
    "    clf = KnnClassifier(n_neighbors=7, metric='cosine')\n",
    "    \n",
    "    # If demonstrative load less samples\n",
    "    if DEMO: X_train, y_train = X_train[:3000], y_train[:3000]\n",
    "    \n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Use the classifier to predict labels for the validation set\n",
    "    y_pred = clf.predict(X_val)\n",
    "\n",
    "    # Generate a classification report for the predictions\n",
    "    report = classification_report(y_val, y_pred, labels=np.unique(y_val), \n",
    "                                   output_dict=True)\n",
    "\n",
    "    # Extract the macro average f1-score from the report\n",
    "    f1 = report['macro avg']['f1-score']\n",
    "\n",
    "    # Print the macro average f1-score\n",
    "    print(f'Fold {K}: Validating MAE 7-NN classifier:\\n\\tMacro avg f1:{f1}')\n",
    "\n",
    "    # Save the report to a CSV file if not demonstrative\n",
    "    if not DEMO:\n",
    "        pd.DataFrame(report).T.to_csv(f'../data/interim/mae_7nn_k{K}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a9a19",
   "metadata": {},
   "source": [
    "## Unsupervised clustering\n",
    "\n",
    "In our previous experiments, we tested deep and shallow learning models for a supervised learning task. We are now interested in evaluating whether it is possible to use the generated embeddings for an unsupervised learning task. To do this, we will use clustering algorithms to see if the generated embeddings can be used to group similar data points together. We will evaluate the performance of the clustering using various metrics to determine its effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e001c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltoolbox.clustering import kMeans\n",
    "from mltoolbox.metrics import silhouette_report\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887e3b2",
   "metadata": {},
   "source": [
    "This function allows to perform clustering and evaluate its performance using two metrics: \n",
    "- silhouette coefficient\n",
    "- adjusted rand index. \n",
    "\n",
    "We use a simple k-Means as clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "495c8250-5f56-4619-a6ba-3d30bb7f323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_single_run(fname, X, y, k, pbar):\n",
    "    # Initialize and fit a KMeans clustering model\n",
    "    kmeans = kMeans(n_clusters=k)\n",
    "    kmeans.fit(X, scale_data=False)\n",
    "    \n",
    "    # Use the model to predict cluster labels for the input data\n",
    "    y_pred = kmeans.predict(X, scale_data=False)\n",
    "    \n",
    "    # Generate a silhouette report for the predicted labels\n",
    "    report = silhouette_report(X, y_pred, output_dict=True)\n",
    "    \n",
    "    sh = report['macro avg']['sh'] # Get average silhouette\n",
    "    ari = adjusted_rand_score(y, y_pred) # Get adjusted rand index\n",
    "    \n",
    "    # Update the progress bar and set the postfix message\n",
    "    pbar.update(1)\n",
    "    pbar.set_postfix({'current feature':fname, f'{k}-Means sh:': sh, 'ari:':ari})\n",
    "    \n",
    "    return sh, ari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d68bc-a4e7-4b2f-9ef1-0336ae3a5c5b",
   "metadata": {},
   "source": [
    "Being an unsupervised task, we do not know in advance the number of clusters to find, thus we iterate over a set of $k$ of the k-Means. Namely, we vary $k \\in [ \\frac{c}{2} ; 2c]$, where $c$ is the number of labels.\n",
    "\n",
    "We cluster both the multi-modal embeddings and the concatenation of raw features and average the results over the stratified-k-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4250596-8a5a-454f-8b8b-068a62686dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00294b6ebe7640978afcf99dcd388611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da6582596b545baac8931ded4068599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6d0bfcc7a24725bb9f6cb57e892055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ee4017237e454584b25f7d75a35944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ae501d44ca44c1848e78c32cec0f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranges = range(8,33) # Try different k of k-Means\n",
    "# If demonstrative limit the runs\n",
    "if DEMO: ranges = range(8, 15)\n",
    "\n",
    "# Iterate over the folds\n",
    "for K in range(5):\n",
    "    # Initialize dictionaries to store the performance \n",
    "    # metrics for each feature\n",
    "    shs = {'rawcat':[], 'mae':[]}\n",
    "    aris = {'rawcat':[], 'mae':[]}\n",
    "    \n",
    "    # Initialize a progress bar\n",
    "    pbar = tqdm(total=len(ranges)*2)\n",
    "    pbar.set_description(f'Evaluating clusters. Fold {K}')\n",
    "    \n",
    "    # Evaluate only the 'rawcat' and 'mae' features\n",
    "    for fname, feature in features.items():\n",
    "        if fname in ['rawcat', 'mae']:\n",
    "            # Load the pre-trained multimodal embeddings\n",
    "            if fname == 'mae':\n",
    "                feature=pd.read_csv(f'{EMBEDDINGS}/mae_embeddings_k{K}.csv', \n",
    "                                   index_col=[0])\n",
    "\n",
    "            # Retrieve the training and validation datasets for the current fold\n",
    "            X_train, X_val, y_train, y_val = get_datasets(kfolds, K, feature)\n",
    "            \n",
    "            # Combine the training and validation datasets\n",
    "            X = np.vstack([X_train, X_val])\n",
    "            y = np.ravel(np.hstack([y_train, y_val]))\n",
    "            \n",
    "            # If demonstrative, limit the number of samples\n",
    "            if DEMO: X, y = X[:1000], y[:1000]\n",
    "            \n",
    "            # Vary k of k-Means\n",
    "            for k in ranges:\n",
    "                # Evaluate the performance of the K-means model for the current k\n",
    "                sh, ari = cluster_single_run(fname, X, y, k, pbar)\n",
    "                \n",
    "                # Update dictionaries\n",
    "                shs[fname].append(sh)\n",
    "                aris[fname].append(ari)\n",
    "    \n",
    "    # If not demonstrative finalize the experiments and save the report\n",
    "    if not DEMO:\n",
    "        # Manage silhouette reports\n",
    "        sh_df = pd.DataFrame(shs, index=ranges)\\\n",
    "                  .rename(columns={x:f'sh_{x}' for x in shs.keys()})\n",
    "        # Manage adjusted rand index reports\n",
    "        ar_df = pd.DataFrame(aris, index=ranges)\\\n",
    "                  .rename(columns={x:f'ar_{x}' for x in aris.keys()})\n",
    "        df = sh_df.reset_index().merge(\n",
    "            ar_df.reset_index(), on='index').set_index('index')\n",
    "        df.to_csv(f'{INTERIM}/clustering_k{K}.csv')\n",
    "    \n",
    "    # Close the progress bar\n",
    "    pbar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "81dc8a169688350846d75f5b64795c14310fd5665d0ae2bea435e43803ad8b3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
