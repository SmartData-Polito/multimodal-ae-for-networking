{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77de2d6b",
   "metadata": {},
   "source": [
    "# <b>Datasets Characterization</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "09238324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mltoolbox and utls reachable from this folder\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from mltoolbox.representation import iWord2Vec\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "DEMO = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e42bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task01 - Mobile Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c550eae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44045, 234)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../data/task01/raw_data/mirage.csv', index_col=[0])\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9bc5f0",
   "metadata": {},
   "source": [
    "### Quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8ee95ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44045, 73)\n",
      "(44045, 129)\n",
      "(44045, 33)\n"
     ]
    }
   ],
   "source": [
    "statistics = dataset[[c for c in dataset.columns if 'stats' in c]+['label']]\n",
    "print(statistics.shape)\n",
    "if not DEMO: \n",
    "    statistics.to_csv('../data/task01/features/statistics.csv')\n",
    "\n",
    "sequences = dataset[[c for c in dataset.columns if 'seq' in c]+['label']]\n",
    "print(sequences.shape)\n",
    "if not DEMO: \n",
    "    sequences.to_csv('../data/task01/features/sequences.csv')\n",
    "\n",
    "payload = dataset[[c for c in dataset.columns if 'byte' in c]+['label']]\n",
    "print(payload.shape)\n",
    "if not DEMO:\n",
    "    payload.to_csv('../data/task01/features/payload.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1468df",
   "metadata": {},
   "source": [
    "### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "978f80cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44045, 65)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air.com.hypah.io.slither_00_00</th>\n",
       "      <td>-0.007959</td>\n",
       "      <td>0.155493</td>\n",
       "      <td>0.199439</td>\n",
       "      <td>-0.003498</td>\n",
       "      <td>0.050787</td>\n",
       "      <td>-0.047075</td>\n",
       "      <td>-0.004645</td>\n",
       "      <td>-0.045098</td>\n",
       "      <td>-0.017566</td>\n",
       "      <td>0.046705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045538</td>\n",
       "      <td>-0.063104</td>\n",
       "      <td>-0.120783</td>\n",
       "      <td>-0.024931</td>\n",
       "      <td>-0.074216</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.047665</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>-0.071530</td>\n",
       "      <td>air.com.hypah.io.slither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air.com.hypah.io.slither_00_01</th>\n",
       "      <td>-0.214694</td>\n",
       "      <td>0.535823</td>\n",
       "      <td>0.770899</td>\n",
       "      <td>-0.120575</td>\n",
       "      <td>-0.326864</td>\n",
       "      <td>-0.061792</td>\n",
       "      <td>-0.296117</td>\n",
       "      <td>0.182108</td>\n",
       "      <td>-0.205998</td>\n",
       "      <td>0.211606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418786</td>\n",
       "      <td>-0.241119</td>\n",
       "      <td>-0.648396</td>\n",
       "      <td>0.072230</td>\n",
       "      <td>-0.723647</td>\n",
       "      <td>-0.171786</td>\n",
       "      <td>0.185587</td>\n",
       "      <td>0.026165</td>\n",
       "      <td>0.029002</td>\n",
       "      <td>air.com.hypah.io.slither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air.com.hypah.io.slither_00_02</th>\n",
       "      <td>-0.214694</td>\n",
       "      <td>0.535823</td>\n",
       "      <td>0.770899</td>\n",
       "      <td>-0.120575</td>\n",
       "      <td>-0.326864</td>\n",
       "      <td>-0.061792</td>\n",
       "      <td>-0.296117</td>\n",
       "      <td>0.182108</td>\n",
       "      <td>-0.205998</td>\n",
       "      <td>0.211606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418786</td>\n",
       "      <td>-0.241119</td>\n",
       "      <td>-0.648396</td>\n",
       "      <td>0.072230</td>\n",
       "      <td>-0.723647</td>\n",
       "      <td>-0.171786</td>\n",
       "      <td>0.185587</td>\n",
       "      <td>0.026165</td>\n",
       "      <td>0.029002</td>\n",
       "      <td>air.com.hypah.io.slither</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0         1         2         3  \\\n",
       "index                                                                    \n",
       "air.com.hypah.io.slither_00_00 -0.007959  0.155493  0.199439 -0.003498   \n",
       "air.com.hypah.io.slither_00_01 -0.214694  0.535823  0.770899 -0.120575   \n",
       "air.com.hypah.io.slither_00_02 -0.214694  0.535823  0.770899 -0.120575   \n",
       "\n",
       "                                       4         5         6         7  \\\n",
       "index                                                                    \n",
       "air.com.hypah.io.slither_00_00  0.050787 -0.047075 -0.004645 -0.045098   \n",
       "air.com.hypah.io.slither_00_01 -0.326864 -0.061792 -0.296117  0.182108   \n",
       "air.com.hypah.io.slither_00_02 -0.326864 -0.061792 -0.296117  0.182108   \n",
       "\n",
       "                                       8         9  ...        55        56  \\\n",
       "index                                               ...                       \n",
       "air.com.hypah.io.slither_00_00 -0.017566  0.046705  ... -0.045538 -0.063104   \n",
       "air.com.hypah.io.slither_00_01 -0.205998  0.211606  ... -0.418786 -0.241119   \n",
       "air.com.hypah.io.slither_00_02 -0.205998  0.211606  ... -0.418786 -0.241119   \n",
       "\n",
       "                                      57        58        59        60  \\\n",
       "index                                                                    \n",
       "air.com.hypah.io.slither_00_00 -0.120783 -0.024931 -0.074216  0.004015   \n",
       "air.com.hypah.io.slither_00_01 -0.648396  0.072230 -0.723647 -0.171786   \n",
       "air.com.hypah.io.slither_00_02 -0.648396  0.072230 -0.723647 -0.171786   \n",
       "\n",
       "                                      61        62        63  \\\n",
       "index                                                          \n",
       "air.com.hypah.io.slither_00_00  0.047665  0.008133 -0.071530   \n",
       "air.com.hypah.io.slither_00_01  0.185587  0.026165  0.029002   \n",
       "air.com.hypah.io.slither_00_02  0.185587  0.026165  0.029002   \n",
       "\n",
       "                                                   label  \n",
       "index                                                     \n",
       "air.com.hypah.io.slither_00_00  air.com.hypah.io.slither  \n",
       "air.com.hypah.io.slither_00_01  air.com.hypah.io.slither  \n",
       "air.com.hypah.io.slither_00_02  air.com.hypah.io.slither  \n",
       "\n",
       "[3 rows x 65 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/task01/raw_data/corpus.txt', 'r') as file:\n",
    "    corpus = [x.split(',') for x in file.read().split('\\n')]\n",
    "\n",
    "# Initialize the model\n",
    "word2vec = iWord2Vec(c=25, e=64, epochs=1, seed=15)\n",
    "# Train the initialized model\n",
    "word2vec.train(corpus)\n",
    "# Retrieve the embeddings after the first training\n",
    "embeddings = word2vec.get_embeddings()\n",
    "\n",
    "embeddings = embeddings.reindex(dataset['s_ip']).set_index(dataset.index)\n",
    "embeddings['label'] = dataset.label\n",
    "\n",
    "if not DEMO:\n",
    "    embeddings.to_csv('../data/task01/features/ipaddress.csv')\n",
    "\n",
    "print(embeddings.shape) # Get the vocabulary size and the embeddings size\n",
    "embeddings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d229e",
   "metadata": {},
   "source": [
    "### Stratified k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28f62bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load stratified k folds\n",
    "kfolds = joblib.load(f'../data/task01/skfolds/folds.save')\n",
    "\n",
    "len(kfolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a730b-e6ea-4be1-9d2f-d54475fd3157",
   "metadata": {},
   "source": [
    "## Task02 - Darknet IP Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "96a7deaf-41a4-4313-a812-5b03d38046c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10460, 46)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics = pd.read_csv('../data/task02/features/statistics.csv', index_col=[0])\n",
    "statistics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "f5bec320-e56e-4a5b-b1ce-5bb3b8616281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b061c9dfee77466a955e6ac4c1f868b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with open('../data/task02/raw_data/corpus_ips.json', 'r') as file:\n",
    "    _corpus = json.loads(file.read())\n",
    "\n",
    "keys = sorted(_corpus.keys())\n",
    "\n",
    "corpus = [x.split(',') for x in _corpus[keys[0]].split('\\n')]\n",
    "\n",
    "# Initialize a progress bar with a total of 5 iterations (skf)\n",
    "pbar = tqdm(total=31)\n",
    "pbar.set_description(f'Training iWord2Vec on 31 days')\n",
    "\n",
    "# Initialize the model\n",
    "word2vec = iWord2Vec(c=5, e=200, epochs=1, seed=15)\n",
    "# Train the initialized model\n",
    "word2vec.train(corpus)\n",
    "# Update the progress bar object and set the postfix message\n",
    "pbar.update(1)\n",
    "for key in keys[1:]:\n",
    "    corpus = [x.split(',') for x in _corpus[key].split('\\n')]\n",
    "    # Update the pre-trained model on the current day\n",
    "    word2vec.update(corpus)\n",
    "    # Update the progress bar object and set the postfix message\n",
    "    pbar.update(1)\n",
    "# Close the progressbar\n",
    "pbar.close()\n",
    "# Retrieve the final updated embeddings\n",
    "embeddings = word2vec.get_embeddings()\n",
    "embeddings = embeddings.reindex(statistics.index)\n",
    "embeddings['label'] = statistics.label\n",
    "if not DEMO:\n",
    "    embeddings.to_csv('../data/task02/features/ipaddress.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "c75a1372-78f7-4bef-b90a-0eb946fadcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e931c3931c45ca88bfbc674a30eb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with open('../data/task02/raw_data/corpus_ports.json', 'r') as file:\n",
    "    _corpus = json.loads(file.read())\n",
    "\n",
    "keys = sorted(_corpus.keys())\n",
    "\n",
    "corpus = [x.split(',') for x in _corpus[keys[0]].split('\\n')]\n",
    "\n",
    "# Initialize a progress bar with a total of 5 iterations (skf)\n",
    "pbar = tqdm(total=31)\n",
    "pbar.set_description(f'Training iWord2Vec on 31 days')\n",
    "\n",
    "# Initialize the model\n",
    "word2vec = iWord2Vec(c=5, e=128, epochs=1, seed=15)\n",
    "# Train the initialized model\n",
    "word2vec.train(corpus)\n",
    "# Update the progress bar object and set the postfix message\n",
    "pbar.update(1)\n",
    "for key in keys[1:]:\n",
    "    corpus = [x.split(',') for x in _corpus[key].split('\\n')]\n",
    "    # Update the pre-trained model on the current day\n",
    "    word2vec.update(corpus)\n",
    "    # Update the progress bar object and set the postfix message\n",
    "    pbar.update(1)\n",
    "# Close the progressbar\n",
    "pbar.close()\n",
    "# Retrieve the final updated embeddings\n",
    "p_embeddings = word2vec.get_embeddings()\n",
    "\n",
    "if not DEMO:\n",
    "    p_embeddings.to_csv('../data/task02/features/ports_w2v.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "4f2245d0-81aa-4ce8-a3d0-38c7021622b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lookup = pd.read_csv('../data/task02/raw_data/ip_port_lookup.csv', index_col=[0])\n",
    "grouped = lookup.groupby('src_ip').agg({'dst_port':list, 'freq':list})\n",
    "\n",
    "ports_embeddings = []\n",
    "for ip in grouped.index:\n",
    "    entry = grouped.loc[ip].dst_port\n",
    "    p_weights = grouped.loc[ip].freq\n",
    "    p_weights = np.asarray(p_weights).reshape(-1, 1)\n",
    "    p_emb = p_embeddings.loc[[str(x) for x in entry]]\n",
    "    a = (p_emb.values* p_weights).sum(0).reshape(1, -1)\n",
    "    avg_embedding = np.ravel(a/len(entry))\n",
    "    ports_embeddings.append(([ip]+list(avg_embedding)))\n",
    "ports_embeddings = pd.DataFrame(ports_embeddings).rename(columns={0:'index'}).set_index('index').reindex(statistics.index)\n",
    "ports_embeddings['label'] = statistics.label\n",
    "\n",
    "if not DEMO:\n",
    "    ports_embeddings.to_csv('../data/task02/features/ports.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a5af4-ef36-43e0-add1-cc89211401e7",
   "metadata": {},
   "source": [
    "### Stratified k-fold **REDO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "f798d6ae-cb5f-4a0b-a858-a619f380161d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load stratified k folds\n",
    "kfolds = joblib.load(f'../data/task02/skfolds/folds.save')\n",
    "\n",
    "len(kfolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce46437-ea67-4b1d-829b-70b41b957028",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task03 - Traffic Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d56a19c7-3951-404a-919c-dec7df2a57fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609, 234)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../data/task03/raw_data/iscxvpn2016.csv', index_col=[0])\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c81f80-c1b9-466e-9efd-16a77d9fad79",
   "metadata": {},
   "source": [
    "### Quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6706c07-2088-4efd-9e2c-a67deab7092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(609, 73)\n",
      "(609, 129)\n",
      "(609, 33)\n"
     ]
    }
   ],
   "source": [
    "statistics = dataset[[c for c in dataset.columns if 'stats' in c]+['label']]\n",
    "print(statistics.shape)\n",
    "if not DEMO: \n",
    "    statistics.to_csv('../data/task03/features/statistics.csv')\n",
    "\n",
    "sequences = dataset[[c for c in dataset.columns if 'seq' in c]+['label']]\n",
    "print(sequences.shape)\n",
    "if not DEMO: \n",
    "    sequences.to_csv('../data/task03/features/sequences.csv')\n",
    "\n",
    "payload = dataset[[c for c in dataset.columns if 'byte' in c]+['label']]\n",
    "print(payload.shape)\n",
    "if not DEMO:\n",
    "    payload.to_csv('../data/task03/features/payload.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174eb1b-7d53-48ae-84c7-040680e404c8",
   "metadata": {},
   "source": [
    "### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5bee89c-3ffd-44cf-b88d-2514abcd5acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(609, 65)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>facebook_video1a_00</th>\n",
       "      <td>0.011131</td>\n",
       "      <td>-0.003477</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>-0.001959</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>-0.01457</td>\n",
       "      <td>-0.016698</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>-0.000364</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>-0.013135</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.006722</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>-0.001108</td>\n",
       "      <td>-0.006213</td>\n",
       "      <td>voip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook_video1a_01</th>\n",
       "      <td>0.011131</td>\n",
       "      <td>-0.003477</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>-0.001959</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>-0.01457</td>\n",
       "      <td>-0.016698</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>-0.000364</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>-0.013135</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.006722</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>-0.001108</td>\n",
       "      <td>-0.006213</td>\n",
       "      <td>voip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook_video1b_02</th>\n",
       "      <td>0.009120</td>\n",
       "      <td>-0.013391</td>\n",
       "      <td>-0.007605</td>\n",
       "      <td>-0.008153</td>\n",
       "      <td>0.00916</td>\n",
       "      <td>-0.004614</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>-0.01052</td>\n",
       "      <td>-0.009713</td>\n",
       "      <td>-0.007819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.010249</td>\n",
       "      <td>-0.011330</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>-0.005463</td>\n",
       "      <td>-0.009623</td>\n",
       "      <td>voip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1         2         3        4  \\\n",
       "index                                                                  \n",
       "facebook_video1a_00  0.011131 -0.003477  0.016922  0.000917  0.00242   \n",
       "facebook_video1a_01  0.011131 -0.003477  0.016922  0.000917  0.00242   \n",
       "facebook_video1b_02  0.009120 -0.013391 -0.007605 -0.008153  0.00916   \n",
       "\n",
       "                            5         6        7         8         9  ...  \\\n",
       "index                                                                 ...   \n",
       "facebook_video1a_00 -0.001959  0.008336 -0.01457 -0.016698  0.002706  ...   \n",
       "facebook_video1a_01 -0.001959  0.008336 -0.01457 -0.016698  0.002706  ...   \n",
       "facebook_video1b_02 -0.004614  0.004000 -0.01052 -0.009713 -0.007819  ...   \n",
       "\n",
       "                           55        56        57        58        59  \\\n",
       "index                                                                   \n",
       "facebook_video1a_00  0.005312 -0.000364  0.012002 -0.013135  0.009491   \n",
       "facebook_video1a_01  0.005312 -0.000364  0.012002 -0.013135  0.009491   \n",
       "facebook_video1b_02  0.007337  0.007162  0.010249 -0.011330  0.015718   \n",
       "\n",
       "                           60        61        62        63  label  \n",
       "index                                                               \n",
       "facebook_video1a_00  0.006722 -0.001974 -0.001108 -0.006213   voip  \n",
       "facebook_video1a_01  0.006722 -0.001974 -0.001108 -0.006213   voip  \n",
       "facebook_video1b_02  0.000573 -0.001427 -0.005463 -0.009623   voip  \n",
       "\n",
       "[3 rows x 65 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/task03/raw_data/corpus.txt', 'r') as file:\n",
    "    corpus = [x.split(',') for x in file.read().split('\\n')]\n",
    "\n",
    "# Initialize the model\n",
    "word2vec = iWord2Vec(c=25, e=64, epochs=1, seed=15)\n",
    "# Train the initialized model\n",
    "word2vec.train(corpus)\n",
    "# Retrieve the embeddings after the first training\n",
    "embeddings = word2vec.get_embeddings()\n",
    "\n",
    "embeddings = embeddings.reindex(dataset['s_ip']).set_index(dataset.index)\n",
    "embeddings['label'] = dataset.label\n",
    "\n",
    "if not DEMO:\n",
    "    embeddings.to_csv('../data/task03/features/ipaddress.csv')\n",
    "\n",
    "print(embeddings.shape) # Get the vocabulary size and the embeddings size\n",
    "embeddings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3e8a3-811b-4727-9eb4-447fe5487fe5",
   "metadata": {},
   "source": [
    "### Stratified k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b4dac46-3e21-451a-ba1f-c310f5712979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load stratified k folds\n",
    "kfolds = joblib.load(f'../data/task03/skfolds/folds.save')\n",
    "\n",
    "len(kfolds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7752e352c355b3ac8de75594c3972c357c3b0b08f713d3e5a9c1d8631c75ec52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
